{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41227311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 12:56:43.612993: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os        \n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import PIL.Image\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    " \n",
    "img_width, img_height = 224, 224\n",
    "nb_train_samples =210\n",
    "nb_validation_samples = 90\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Defines & compiles the model\n",
    "model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=input_shape),\n",
    "tf.keras.layers.MaxPooling2D(2, 2),\n",
    "keras.layers.Dropout(rate=0.15), #adding dropout regularization throughout the model to deal with overfitting\n",
    "# The second convolution\n",
    "tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "keras.layers.Dropout(rate=0.1),\n",
    "# The third convolution\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "keras.layers.Dropout(rate=0.10),\n",
    "# Flatten the results to feed into a DNN\n",
    "tf.keras.layers.Flatten(),\n",
    "# 512 neuron hidden layer\n",
    "tf.keras.layers.Dense(512, activation='relu'),\n",
    "\n",
    "# 3 output neuron for the 3 classes of Animal Images\n",
    "tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['acc'])\n",
    "        \n",
    "\n",
    "# Creates an instance of an ImageDataGenerator called train_datagen, and a train_generator, train_datagen.flow_from_directory\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#splits data into training and testing(validation) sets\n",
    "train_datagen =ImageDataGenerator(rescale=1./255, validation_split=0.25)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "   \n",
    "#training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/Users/poojahiregoudar/desktop/pooja/project/Image-Classification/Furniture',  # Source directory\n",
    "        target_size=(img_width, img_height),  # Resizes images\n",
    "        batch_size=15,\n",
    "        class_mode='categorical',subset = 'training')\n",
    "    \n",
    "\n",
    "epochs = 5\n",
    "#Testing data\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "'/Users/poojahiregoudar/desktop/pooja/project/Image-Classification/Furniture',\n",
    "target_size=(img_width, img_height),\n",
    "batch_size=15,\n",
    "class_mode='categorical',\n",
    "subset='validation') # set as validation data\n",
    "       \n",
    "#Model fitting for a number of epochs\n",
    "history = model.fit(\n",
    "train_generator,\n",
    "steps_per_epoch=nb_train_samples // batch_size,\n",
    "epochs=epochs,\n",
    "validation_data = validation_generator,\n",
    "validation_steps = nb_validation_samples // batch_size,\n",
    "verbose=1)\n",
    "    \n",
    "        \n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "#This code is used to plot the training and validation accuracy\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    " \n",
    "# returns accuracy of training\n",
    "print(\"Training Accuracy:\"), print(history.history['acc'][-1])\n",
    "print(\"Testing Accuracy:\"), print (history.history['val_acc'][-1])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0d0241e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 162ms/step\n",
      "Predicted Class (0 - Bed , 1- Chair , 2 - Sofa):  [0.09984678 0.00260657 0.8975466 ]\n"
     ]
    }
   ],
   "source": [
    "##model = load_model('/Users/poojahiregoudar/desktop/pooja/project/classification/model_saved.h5')\n",
    "# new_model = tf.keras.models.load_model('/Users/poojahiregoudar/desktop/pooja/project/classification/model_saved.h5')\n",
    "image = load_img('/Users/poojahiregoudar/desktop/pooja/project/classification/Bag sofa velvet green.jpg', target_size=(224, 224))\n",
    "img = np.array(image)\n",
    "img = np.expand_dims(img, axis=0)   \n",
    "img = img / 255.0\n",
    "img = img.reshape(1,224,224,3)\n",
    "label = model.predict(img)\n",
    "print(\"Predicted Class (0 - Bed , 1- Chair , 2 - Sofa): \", label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d678f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "002c716b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09984678, 0.00260657, 0.8975466 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cfddfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f7cc703d-3025-4e45-9215-76f07d325ce1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f7cc703d-3025-4e45-9215-76f07d325ce1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dumped\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'final_model.pkl')\n",
    "print(\"Model dumped\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "793559d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('final_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad71071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:4444\n",
      " * Running on http://10.0.0.116:4444\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:10.0.0.116 - - [22/Feb/2023 13:52:12] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:10.0.0.116 - - [22/Feb/2023 13:52:12] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Your API definition\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if model:\n",
    "        try:\n",
    "            json_ = request.json\n",
    "            print(json_)\n",
    "            image = load_img('/Users/poojahiregoudar/desktop/pooja/project/classification/Bag sofa velvet green.jpg', target_size=(224, 224))\n",
    "            img = np.array(image)\n",
    "            img = np.expand_dims(img, axis=0)   \n",
    "            img = img / 255.0\n",
    "            img = img.reshape(1,224,224,3)\n",
    "            label = model.predict(img)\n",
    "            print(\"Predicted Class (0 - Bed , 1- Chair , 2 - Sofa): \", label[0])\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            return jsonify({'prediction': str(prediction)})\n",
    "\n",
    "        except:\n",
    "\n",
    "            return jsonify({'trace': traceback.format_exc()})\n",
    "    else:\n",
    "        print ('Train the model first')\n",
    "        return ('No model here to use')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=os.getenv('IP', '0.0.0.0'),\n",
    "            port=int(os.getenv('PORT',4444)))\n",
    "#     try:\n",
    "#         port = int(sys.argv[1]) # This is for a command-line input\n",
    "#     except:\n",
    "#         port = 4444 # If you don't provide any port the port will be set to 12345\n",
    "\n",
    "    model = joblib.load(\"final_model.pkl\") # Load \"model.pkl\"\n",
    "    print ('Model loaded')\n",
    "    \n",
    "    app.run(port=port, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9599148e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
